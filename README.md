ğŸ” LangIndex â€“ On-Device RAG SDK for Android

Fast, Lightweight, Privacy-Preserving Context Retrieval for LLMs

LangIndex is an on-device RAG (Retrieval-Augmented Generation) SDK for Android.It allows you to store and retrieve embeddings locally without relying on cloud-based vector DBs.

Built for privacy-first AI apps and offline AI agents.Optimized for integrating with both on-device and remote LLMs.

â­ Key Features

ğŸ‘‰ On-Device Storage â€“ Stores embeddings using ObjectBox.ğŸ‘‰ Semantic Search â€“ Cosine similarity search over embeddings.ğŸ‘‰ MediaPipe Embeddings â€“ Uses TextEmbedder (MobileBERT / Average Word) models.ğŸ‘‰ Tokenizer Included â€“ JTokkit-based tokenization for LLM compatibility.ğŸ‘‰ Offline RAG â€“ Helps build LLM-powered apps with local context.ğŸ‘‰ Open-Source & Easy to Integrate.

ğŸ“¦ Installation

Add JitPack to your projectâ€™s settings.gradle.kts:

dependencyResolutionManagement {
repositories {
google()
mavenCentral()
maven("https://jitpack.io")
}
}

Add LangIndex dependency to your app/build.gradle.kts:

dependencies {
implementation("com.github.vishalcs106:langindex:1.0.2")
}

ğŸš€ Usage

1. Build LangIndex Instance

val langIndex = LangIndex.Builder()
.setModel(ModelType.AVERAGE_WORD) // or ModelType.MOBILE_BERT
.build(context)

2. Process a Message

val result = langIndex.processMessage("Tell me about Deadpool")

3. Access Results

val tokens: List<String> = result.tokens
val embedding: FloatArray = result.embedding
val retrievedChunks: List<String> = result.retrievedChunks

ğŸ’  Example

val langIndex = LangIndex.Builder().build(context)

val result = langIndex.processMessage("Tell me about Deadpool")

Log.d("Tokens", result.tokens.toString())
Log.d("Embedding", result.embedding.joinToString())
Log.d("Retrieved Chunks", result.retrievedChunks.toString())

ğŸ’¨ Real-World Use Case

Integrate LangIndex with Google Gemini, GPT, or LLaMA:

Retrieve relevant context from on-device storage.

Send retrieved context + user query to an LLM for better responses.

Maintain user privacy â€“ No need to upload personal data for RAG!

ğŸ“‚ Models Used

LangIndex uses MediaPipe TextEmbedder:

Model

Size

MOBILE_BERT

20 MB

More accurate, better semantic understanding.

Models are auto-downloaded on first build and stored in assets/.

ğŸ“š How It Works

Tokenizes the message using JTokkit.

Generates embeddings using MediaPipe TextEmbedder.

Stores embeddings locally using ObjectBox.

Performs similarity search (cosine similarity) on stored embeddings.

Returns the top `` relevant text chunks along with tokens and the new embedding.

ğŸ‘¨â€ğŸ’» Contributing

Feel free to submit issues, feature requests, or pull requests.

ğŸ’Ÿ License

Apache 2.0

ğŸš€ Author

ğŸ‘‹ Vishal Madhava â€“ LinkedIn | Twitter

LangIndex is a first-principles RAG solution built with a vision for privacy-first AI on Android.LFG! ğŸš€

